#!/usr/bin/env bash
set -euo pipefail

AUDIO="${1:-audio/4_2.wav}"
BASE_SRT="${2:-subs/final_aligned_perfect.srt}"
SCRIPT_TXT="${3:-script_4_2.txt}"
OUT_SRT="${4:-subs/final_merged.srt}"
OUT_VTT="${5:-subs/final_merged.vtt}"

PYTHON="${PYTHON:-python3}"

err(){ echo "ERROR: $*" >&2; exit 1; }

[[ -f "$AUDIO" ]]     || err "éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $AUDIO"
[[ -f "$BASE_SRT" ]]  || err "SRTãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $BASE_SRT"
[[ -f "$SCRIPT_TXT" ]]|| err "å°æœ¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $SCRIPT_TXT"

# 1) æ—¢å­˜SRTã®æœ«å°¾ç§’ã‚’å–å¾—ï¼ˆ0.10sæ‰‹å‰ã‹ã‚‰åˆ‡ã‚Šå‡ºã™ï¼‰
START="$(
$PYTHON - <<PY
import re, pathlib
p=pathlib.Path("$BASE_SRT").read_text(encoding='utf-8')
last=0.0
for b in re.split(r'\n\s*\n', p.strip()):
    ls=[ln for ln in b.splitlines() if ln.strip()]
    if not ls: continue
    if re.fullmatch(r'\d+', ls[0]): ls=ls[1:]
    if not ls: continue
    m=re.match(r'^(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', ls[0])
    if not m: continue
    h,mn,ssms=m.group(2).split(':'); s,ms=ssms.split(',')
    end=int(h)*3600+int(mn)*60+int(s)+int(ms)/1000.0
    last=end
print(max(0.0,last-0.10))
PY
)"
echo "â± æœ«å°¾é–‹å§‹ç§’: $START"

# 2) å°¾éƒ¨åˆ‡ã‚Šå‡ºã—ï¼ˆWAVã¯ -c copy ã ã¨ç©ºã«ãªã‚Šå¾—ã‚‹â†’ PCM å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ç¢ºå®ŸåŒ–ï¼‰
rm -f audio/tail.wav
ffmpeg -y -i "$AUDIO" -ss "$START" -c:a pcm_s16le -ar 24000 -ac 1 audio/tail.wav -loglevel error || true
if [[ ! -s audio/tail.wav ]]; then
  echo "âš ï¸ å†è©¦è¡Œ: -ss ã‚’å…¥åŠ›ã®å‰ã¸ç§»å‹•"
  ffmpeg -y -ss "$START" -i "$AUDIO" -c:a pcm_s16le -ar 24000 -ac 1 audio/tail.wav -loglevel error
fi
[[ -s audio/tail.wav ]] || err "tail.wav ãŒç©ºã§ã™ã€‚START=$START ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

# 3) venv æœ€å°ä¾å­˜ã‚»ãƒƒãƒˆ
if [[ ! -d venv ]]; then
  echo "ğŸ“¦ venv ã‚’ä½œæˆã—ã¾ã™"
  $PYTHON -m venv venv
fi
source venv/bin/activate
python -V

python - <<PY || NEED="yes"
import importlib, sys
for m in ["faster_whisper","numpy","ctranslate2","huggingface_hub","tokenizers","onnxruntime"]:
    try: importlib.import_module(m)
    except Exception: sys.exit(1)
print("deps-ok")
PY
if [[ "${NEED:-}" == "yes" ]]; then
  echo "ğŸ“¥ ä¾å­˜å°å…¥ï¼ˆæœ€å°ã‚»ãƒƒãƒˆï¼‰"
  pip install -U pip
  pip install "faster-whisper==1.0.3" numpy==1.26.4 ctranslate2 huggingface-hub tokenizers onnxruntime
fi

# 4) Whisper å¼·åˆ¶ã‚¢ãƒ©ã‚¤ãƒ³ï¼ˆå°¾éƒ¨ï¼‰
python scripts/force_align_whisper.py \
  --audio audio/tail.wav \
  --script "$SCRIPT_TXT" \
  --out subs/tail_aligned.srt \
  --model medium \
  --device cpu

[[ -s subs/tail_aligned.srt ]] || err "subs/tail_aligned.srt ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"

# 5) è¿½ã„SRTã‚’ +120ms ã‚ªãƒ•ã‚»ãƒƒãƒˆã§çµåˆï¼ˆæœ€å°ã‚®ãƒ£ãƒƒãƒ—80ms / æœ€å°é•·0.80sï¼‰
python scripts/srt_offset_merge.py \
  --base "$BASE_SRT" \
  --add  subs/tail_aligned.srt \
  --gap_ms 120 \
  --out "$OUT_SRT" \
  --out_vtt "$OUT_VTT"

# 6) å®Ÿå°ºæ¤œè¨¼
python - <<PY
import wave, contextlib, re, pathlib
def dur(w): 
    with contextlib.closing(wave.open(w,'rb')) as f: 
        return f.getnframes()/f.getframerate()
def last_end(s):
    t=pathlib.Path(s).read_text(encoding='utf-8').strip()
    last=0.0
    for b in re.split(r'\n\s*\n', t):
        ls=[ln for ln in b.splitlines() if ln.strip()]
        if ls and re.fullmatch(r'\d+', ls[0]): ls=ls[1:]
        if not ls: continue
        m=re.match(r'^(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', ls[0])
        if not m: continue
        h,mn,ssms=m.group(2).split(':'); s,ms=ssms.split(',')
        end=int(h)*3600+int(mn)*60+int(s)+int(ms)/1000.0
        last=end
    return last
audio = dur("$AUDIO")
end   = last_end("$OUT_SRT")
print(f'âœ… DONE  audio={audio:.3f}s  srt_end={end:.3f}s  diff={end-audio:+.3f}s')
PY

echo "ğŸ“„ å‡ºåŠ›: $OUT_SRT / $OUT_VTT"