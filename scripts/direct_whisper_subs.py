#!/usr/bin/env python3
"""
Direct Whisper Subtitle Generation - Simple & Reliable

å˜ç´”ã§ç¢ºå®ŸãªWhisperãƒ™ãƒ¼ã‚¹å­—å¹•ç”Ÿæˆã€‚è¤‡é›‘ãªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãªã—ã€‚
Whisperã®èªè­˜çµæœã‚’ãã®ã¾ã¾ä¿¡é ¼ã™ã‚‹å®Ÿç”¨çš„æ‰‹æ³•ã€‚
"""

import whisper
import os
import re
import unicodedata
from typing import List, Dict, Any


def load_whisper_model(model_size: str = "medium") -> whisper.Whisper:
    """Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
    print(f"ğŸ¤– Loading Whisper {model_size} model...")
    model = whisper.load_model(model_size)
    print("âœ… Model loaded successfully")
    return model


def transcribe_audio(model: whisper.Whisper, audio_path: str) -> Dict[str, Any]:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’éŸ³å£°èªè­˜"""
    print(f"ğŸµ Transcribing: {audio_path}")
    
    # Whisperã§èªè­˜å®Ÿè¡Œ
    result = model.transcribe(
        audio_path,
        language="ja",  # æ—¥æœ¬èªæŒ‡å®š
        word_timestamps=True,  # å˜èªãƒ¬ãƒ™ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        verbose=False
    )
    
    print(f"âœ… Transcription complete")
    print(f"ğŸ“Š Detected segments: {len(result['segments'])}")
    
    return result


def format_timestamp(seconds: float) -> str:
    """ç§’ã‚’SRTå½¢å¼ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¤‰æ›"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def clean_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã®åŸºæœ¬çš„ãªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    # NFKCæ­£è¦åŒ–
    text = unicodedata.normalize("NFKC", text)
    
    # ä½™åˆ†ãªç©ºç™½å‰Šé™¤
    text = re.sub(r'\s+', '', text)
    
    # åŸºæœ¬çš„ãªæ•´å½¢
    text = text.strip()
    
    return text


def ensure_line_breaks(text: str, max_chars: int = 15) -> str:
    """é©åˆ‡ãªæ”¹è¡Œã‚’æŒ¿å…¥"""
    if len(text) <= max_chars:
        return text
    
    # æ—¥æœ¬èªå¥èª­ç‚¹ã§ã®åˆ†å‰²ã‚’è©¦è¡Œ
    punctuation = "ã€‚ï¼ï¼Ÿã€"
    
    # å¥èª­ç‚¹ã§åˆ†å‰²å¯èƒ½ãªä½ç½®ã‚’æ¢ã™
    for i, char in enumerate(text):
        if char in punctuation and i < max_chars:
            first_part = text[:i+1]
            second_part = text[i+1:]
            if second_part:
                return first_part + "\n" + ensure_line_breaks(second_part, max_chars)
    
    # å¥èª­ç‚¹ãŒãªã„å ´åˆã¯æ–‡å­—æ•°ã§åˆ†å‰²
    mid = min(max_chars, len(text) // 2)
    return text[:mid] + "\n" + text[mid:]


def optimize_segment_timing(segments: List[Dict]) -> List[Dict]:
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®åŸºæœ¬æœ€é©åŒ–"""
    optimized = []
    
    for i, seg in enumerate(segments):
        start = seg['start']
        end = seg['end']
        text = clean_text(seg['text'])
        
        if not text:
            continue
        
        # æœ€å°è¡¨ç¤ºæ™‚é–“ç¢ºä¿
        min_duration = 1.0
        if end - start < min_duration:
            # å‰å¾Œã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã®é–“éš”ã‚’è€ƒæ…®ã—ã¦å»¶é•·
            if i < len(segments) - 1:
                next_start = segments[i + 1]['start']
                gap = next_start - end
                if gap > 0.1:
                    end = min(end + min_duration - (end - start), next_start - 0.05)
        
        # æ”¹è¡Œå‡¦ç†
        formatted_text = ensure_line_breaks(text)
        
        optimized.append({
            'start': start,
            'end': end,
            'text': formatted_text
        })
    
    return optimized


def write_srt_file(segments: List[Dict], output_path: str) -> None:
    """SRTå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, seg in enumerate(segments, 1):
            start_time = format_timestamp(seg['start'])
            end_time = format_timestamp(seg['end'])
            
            f.write(f"{i}\n")
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{seg['text']}\n\n")
    
    print(f"ğŸ’¾ SRT saved: {output_path}")


def write_vtt_file(segments: List[Dict], output_path: str) -> None:
    """VTTå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›"""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("WEBVTT\n\n")
        
        for i, seg in enumerate(segments, 1):
            start_time = format_timestamp(seg['start']).replace(',', '.')
            end_time = format_timestamp(seg['end']).replace(',', '.')
            
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{seg['text']}\n\n")
    
    print(f"ğŸ’¾ VTT saved: {output_path}")


def generate_subtitles(audio_path: str, model_size: str = "medium") -> None:
    """å­—å¹•ç”Ÿæˆãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ¯ Starting Direct Whisper Subtitle Generation")
    print("=" * 50)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if not os.path.exists(audio_path):
        print(f"âŒ Audio file not found: {audio_path}")
        return
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    model = load_whisper_model(model_size)
    
    # éŸ³å£°èªè­˜
    result = transcribe_audio(model, audio_path)
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæœ€é©åŒ–
    print("ğŸ”§ Optimizing segments...")
    optimized_segments = optimize_segment_timing(result['segments'])
    
    print(f"âœ… Optimized to {len(optimized_segments)} segments")
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    base_name = os.path.splitext(os.path.basename(audio_path))[0]
    srt_path = f"subs/final_production_direct.srt"
    vtt_path = f"subs/final_production_direct.vtt"
    
    # subsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs("subs", exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    write_srt_file(optimized_segments, srt_path)
    write_vtt_file(optimized_segments, vtt_path)
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    total_duration = result['segments'][-1]['end'] if result['segments'] else 0
    avg_segment_duration = total_duration / len(optimized_segments) if optimized_segments else 0
    
    print(f"\nğŸ“Š Generation Summary:")
    print(f"- Total segments: {len(optimized_segments)}")
    print(f"- Total duration: {total_duration:.1f} seconds")
    print(f"- Average segment length: {avg_segment_duration:.1f} seconds")
    print(f"- Output files: {srt_path}, {vtt_path}")
    
    print("\nğŸ‰ Subtitle generation completed successfully!")


if __name__ == "__main__":
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    audio_file = os.path.join(project_root, "audio", "4_2.wav")
    generate_subtitles(audio_file)