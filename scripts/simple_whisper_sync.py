#!/usr/bin/env python3
"""
Simple Whisper Sync - éŸ³å£°åŒæœŸé‡è¦–ã®å­—å¹•ç”Ÿæˆ

éŸ³å£°ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¨ã®åŒæœŸã‚’æœ€å„ªå…ˆã¨ã—ãŸã€ã‚·ãƒ³ãƒ—ãƒ«ã§ç¢ºå®Ÿãªæ‰‹æ³•ã€‚
Whisperã®èªè­˜çµæœã‚’ã§ãã‚‹ã ã‘ãã®ã¾ã¾ä½¿ç”¨ã€‚
"""

import whisper
import os
import re
import unicodedata
from typing import List, Dict, Any


def format_timestamp(seconds: float) -> str:
    """ç§’ã‚’SRTå½¢å¼ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¤‰æ›"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def clean_japanese_text(text: str) -> str:
    """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®åŸºæœ¬ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    # NFKCæ­£è¦åŒ–
    text = unicodedata.normalize("NFKC", text)
    
    # ä½™åˆ†ãªç©ºç™½å‰Šé™¤
    text = re.sub(r'\s+', '', text)
    
    # å‰å¾Œã®ç©ºç™½å‰Šé™¤
    text = text.strip()
    
    return text


def natural_line_break(text: str, max_length: int = 20) -> str:
    """è‡ªç„¶ãªæ”¹è¡ŒæŒ¿å…¥ï¼ˆæ—¥æœ¬èªç”¨ï¼‰"""
    if len(text) <= max_length:
        return text
    
    # æ—¥æœ¬èªã®è‡ªç„¶ãªåŒºåˆ‡ã‚Šæ–‡å­—
    break_chars = "ã€‚ï¼ï¼Ÿã€â€¦"
    
    # æ”¹è¡Œä½ç½®ã‚’æ¢ã™
    best_pos = len(text) // 2
    
    # å¥èª­ç‚¹ã§ã®åˆ†å‰²ã‚’å„ªå…ˆ
    for i in range(min(max_length, len(text))):
        if text[i] in break_chars:
            best_pos = i + 1
            break
    
    # æœ€å¤§é•·ã‚’è¶…ãˆãªã„ã‚ˆã†ã«èª¿æ•´
    if best_pos > max_length:
        best_pos = max_length
    
    if best_pos >= len(text):
        return text
    
    # åˆ†å‰²
    first_line = text[:best_pos]
    second_line = text[best_pos:]
    
    return first_line + '\n' + second_line


def transcribe_with_precise_timing(audio_path: str) -> Dict[str, Any]:
    """éŸ³å£°ã‚’é«˜ç²¾åº¦ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§èªè­˜"""
    print("ğŸ¤– Loading Whisper model...")
    model = whisper.load_model("medium")
    
    print(f"ğŸµ Transcribing with precise timing: {audio_path}")
    
    # Whisperã§èªè­˜ï¼ˆæœ€é«˜ç²¾åº¦è¨­å®šï¼‰
    result = model.transcribe(
        audio_path,
        language="ja",
        word_timestamps=True,
        verbose=True,
        temperature=0,  # æ±ºå®šçš„ãªçµæœã®ãŸã‚
        compression_ratio_threshold=2.4,
        logprob_threshold=-1.0,
        no_speech_threshold=0.6,
        condition_on_previous_text=False  # ã‚ˆã‚Šæ­£ç¢ºãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ãŸã‚
    )
    
    return result


def create_synced_subtitles(result: Dict[str, Any]) -> List[Dict]:
    """éŸ³å£°åŒæœŸå­—å¹•ã‚’ä½œæˆ"""
    segments = []
    
    for segment in result['segments']:
        # ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        text = clean_japanese_text(segment['text'])
        
        if not text:
            continue
        
        # æ”¹è¡Œå‡¦ç†
        formatted_text = natural_line_break(text)
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä½œæˆ
        segments.append({
            'start': segment['start'],
            'end': segment['end'],
            'text': formatted_text,
            'confidence': segment.get('avg_logprob', 0.0)
        })
    
    print(f"âœ… Created {len(segments)} synchronized segments")
    return segments


def save_srt(segments: List[Dict], output_path: str) -> None:
    """SRTãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for i, seg in enumerate(segments, 1):
            start_time = format_timestamp(seg['start'])
            end_time = format_timestamp(seg['end'])
            
            f.write(f"{i}\n")
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{seg['text']}\n\n")
    
    print(f"ğŸ’¾ SRT saved: {output_path}")


def save_vtt(segments: List[Dict], output_path: str) -> None:
    """VTTãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("WEBVTT\n\n")
        
        for seg in segments:
            start_time = format_timestamp(seg['start']).replace(',', '.')
            end_time = format_timestamp(seg['end']).replace(',', '.')
            
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{seg['text']}\n\n")
    
    print(f"ğŸ’¾ VTT saved: {output_path}")


def generate_synced_subtitles(audio_path: str, output_base: str = "subs/final_production") -> None:
    """éŸ³å£°åŒæœŸå­—å¹•ç”Ÿæˆãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ¯ Starting Audio-Synced Subtitle Generation")
    print("=" * 60)
    
    # éŸ³å£°èªè­˜
    result = transcribe_with_precise_timing(audio_path)
    
    # åŒæœŸå­—å¹•ä½œæˆ
    print("ğŸ”„ Creating synchronized subtitles...")
    segments = create_synced_subtitles(result)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    srt_path = f"{output_base}.srt"
    vtt_path = f"{output_base}.vtt"
    
    save_srt(segments, srt_path)
    save_vtt(segments, vtt_path)
    
    # çµ±è¨ˆè¡¨ç¤º
    total_duration = segments[-1]['end'] if segments else 0
    avg_duration = sum(seg['end'] - seg['start'] for seg in segments) / len(segments) if segments else 0
    
    print(f"\nğŸ“Š Generation Summary:")
    print(f"- Total segments: {len(segments)}")
    print(f"- Total duration: {total_duration:.1f} seconds")
    print(f"- Average segment: {avg_duration:.1f} seconds")
    print(f"- SRT file: {srt_path}")
    print(f"- VTT file: {vtt_path}")
    
    print(f"\nğŸ‰ Audio-synced subtitles generated successfully!")
    print("ğŸµ Perfect timing with original audio guaranteed!")


if __name__ == "__main__":
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    audio_file = os.path.join(project_root, "audio", "4_2.wav")
    generate_synced_subtitles(audio_file)